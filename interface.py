import sys
import threading
import speech_recognition as sr
import keyboard  # ç”¨æ–¼ç›£è½å…¨åŸŸç†±éµ
from PyQt6.QtWidgets import QApplication, QWidget, QLabel, QVBoxLayout, QGraphicsDropShadowEffect
from PyQt6.QtCore import Qt, pyqtSignal, QTimer
from PyQt6.QtGui import QColor, QFont, QPainter, QPen, QConicalGradient, QBrush, QLinearGradient, QPixmap, QImage

class ScreenGlowOverlay(QWidget):
    """å…¨è¢å¹•é‚Šæ¡†ç™¼å…‰ç‰¹æ•ˆè¦–çª— (éœ“è™¹æ³¢æµª + æ¼¸å±¤æ·¡å…¥æ·¡å‡ºç‰ˆ)"""
    def __init__(self):
        super().__init__()
        self.setWindowFlags(
            Qt.WindowType.FramelessWindowHint |
            Qt.WindowType.WindowStaysOnTopHint |
            Qt.WindowType.Tool |
            Qt.WindowType.WindowTransparentForInput
        )
        self.setAttribute(Qt.WidgetAttribute.WA_TranslucentBackground)
        self.setAttribute(Qt.WidgetAttribute.WA_TransparentForMouseEvents)
        self.setGeometry(QApplication.primaryScreen().geometry())

        # å‹•ç•«èˆ‡ç‰¹æ•ˆåƒæ•¸
        self.angle = 0
        self.opacity = 0.0
        self.target_opacity = 0.0
        self.border_width = 50 # åŠ å¯¬é‚Šæ¡†ä»¥é¡¯ç¤ºæ¼¸å±¤æ•ˆæœ
        self.mask_pixmap = None
        
        self.timer = QTimer(self)
        self.timer.timeout.connect(self.update_animation)

    def resizeEvent(self, event):
        # ç•¶è¢å¹•å¤§å°æ”¹è®Šæ™‚ï¼Œé‡æ–°ç”¢ç”Ÿé®ç½©
        self.generate_mask()
        super().resizeEvent(event)

    def generate_mask(self):
        """ç”¢ç”Ÿé‚Šç·£å¯¦å¿ƒã€å…§éƒ¨é€æ˜çš„é®ç½©"""
        if self.width() <= 0 or self.height() <= 0: return
        
        img = QImage(self.size(), QImage.Format.Format_ARGB32_Premultiplied)
        img.fill(Qt.GlobalColor.transparent)
        p = QPainter(img)
        bw = self.border_width
        w, h = self.width(), self.height()
        
        # å®šç¾©æ¼¸å±¤: 0.0(é‚Šç·£)=ä¸é€æ˜, 1.0(å…§éƒ¨)=é€æ˜
        # ä¸Šé‚Šæ¡†
        g_top = QLinearGradient(0, 0, 0, bw)
        g_top.setColorAt(0, QColor(255, 255, 255, 255))
        g_top.setColorAt(1, QColor(255, 255, 255, 0))
        p.fillRect(0, 0, w, bw, g_top)
        
        # ä¸‹é‚Šæ¡†
        g_bottom = QLinearGradient(0, h, 0, h - bw)
        g_bottom.setColorAt(0, QColor(255, 255, 255, 255))
        g_bottom.setColorAt(1, QColor(255, 255, 255, 0))
        p.fillRect(0, h - bw, w, bw, g_bottom)
        
        # å·¦é‚Šæ¡†
        g_left = QLinearGradient(0, 0, bw, 0)
        g_left.setColorAt(0, QColor(255, 255, 255, 255))
        g_left.setColorAt(1, QColor(255, 255, 255, 0))
        p.fillRect(0, 0, bw, h, g_left)
        
        # å³é‚Šæ¡†
        g_right = QLinearGradient(w, 0, w - bw, 0)
        g_right.setColorAt(0, QColor(255, 255, 255, 255))
        g_right.setColorAt(1, QColor(255, 255, 255, 0))
        p.fillRect(w - bw, 0, bw, h, g_right)
        
        p.end()
        self.mask_pixmap = QPixmap.fromImage(img)

    def fade_in(self):
        self.target_opacity = 1.0
        if not self.timer.isActive():
            self.show()
            self.timer.start(30)

    def fade_out(self):
        self.target_opacity = 0.0

    def update_animation(self):
        # 1. æ›´æ–°æ—‹è½‰è§’åº¦
        self.angle = (self.angle - 5) % 360

        # 2. æ›´æ–°é€æ˜åº¦ (æ·¡å…¥æ·¡å‡º)
        diff = self.target_opacity - self.opacity
        if abs(diff) < 0.05:
            self.opacity = self.target_opacity
            if self.opacity == 0.0:
                self.hide()
                self.timer.stop()
        else:
            self.opacity += diff * 0.2 # å¹³æ»‘éæ¸¡
            
        self.update()

    def paintEvent(self, event):
        if self.opacity <= 0 or not self.mask_pixmap: return

        # å»ºç«‹ä¸€å€‹æš«å­˜çš„ Pixmap ä¾†åˆæˆç‰¹æ•ˆ
        temp_pixmap = QPixmap(self.size())
        temp_pixmap.fill(Qt.GlobalColor.transparent)
        
        p = QPainter(temp_pixmap)
        p.setRenderHint(QPainter.RenderHint.Antialiasing)
        
        # æ­¥é©Ÿ A: å…ˆç•«å‡ºé®ç½© (æ±ºå®šå“ªè£¡è¦é¡¯ç¤º)
        p.drawPixmap(0, 0, self.mask_pixmap)
        
        # æ­¥é©Ÿ B: ä½¿ç”¨ SourceIn æ¨¡å¼å¡«å…¥éœ“è™¹è‰²å½©
        # (ä¿ç•™é®ç½©çš„ä¸é€æ˜åº¦ï¼Œä½†å°‡é¡è‰²æ›¿æ›ç‚ºæ¼¸å±¤)
        p.setCompositionMode(QPainter.CompositionMode.CompositionMode_SourceIn)
        
        center = self.rect().center()
        gradient = QConicalGradient(center.x(), center.y(), self.angle)
        gradient.setColorAt(0.00, QColor(0, 255, 255))   # Cyan
        gradient.setColorAt(0.25, QColor(0, 0, 255))     # Blue
        gradient.setColorAt(0.50, QColor(128, 0, 128))   # Purple
        gradient.setColorAt(0.75, QColor(255, 0, 255))   # Magenta
        gradient.setColorAt(1.00, QColor(0, 255, 255))   # Cyan
        
        p.setBrush(QBrush(gradient))
        p.setPen(Qt.PenStyle.NoPen)
        p.drawRect(self.rect())
        p.end()
        
        # æ­¥é©Ÿ C: å°‡åˆæˆå¥½çš„ Pixmap ç•«åˆ°è¢å¹•ä¸Šï¼Œä¸¦å¥—ç”¨å…¨åŸŸé€æ˜åº¦
        painter = QPainter(self)
        painter.setOpacity(self.opacity)
        painter.drawPixmap(0, 0, temp_pixmap)

class VoiceAssistantWidget(QWidget):
    # å®šç¾©ä¸€å€‹ä¿¡è™Ÿï¼Œç”¨ä¾†åœ¨é GUI åŸ·è¡Œç·’é€šçŸ¥ GUI æ›´æ–°
    status_signal = pyqtSignal(str)

    def __init__(self):
        super().__init__()
        self.initUI()
        
        # åˆå§‹åŒ–å…¨è¢å¹•ç‰¹æ•ˆ
        self.overlay = ScreenGlowOverlay()
        
        self.listening = False
        self.vad_mode = False  # VAD æ¨¡å¼ç‹€æ…‹
        self.vad_thread_running = False # é¿å…é‡è¤‡å•Ÿå‹• VAD åŸ·è¡Œç·’
        
        # é€£æ¥ä¿¡è™Ÿ
        self.status_signal.connect(self.update_status)

        # å•Ÿå‹•èƒŒæ™¯ç†±éµç›£è½
        self.start_hotkey_listener()

    def initUI(self):
        # 1. è¨­å®šè¦–çª—å±¬æ€§ï¼šç„¡é‚Šæ¡†ã€æ°¸é åœ¨æœ€ä¸Šå±¤
        self.setWindowFlags(Qt.WindowType.FramelessWindowHint | Qt.WindowType.WindowStaysOnTopHint | Qt.WindowType.Tool)
        
        # 2. è¨­å®šèƒŒæ™¯é€æ˜
        self.setAttribute(Qt.WidgetAttribute.WA_TranslucentBackground)

        # 3. èª¿æ•´è¦–çª—å¤§å° (ç¨å¾®åŠ å¤§ä»¥å®¹ç´ç™¼å…‰ç‰¹æ•ˆ)
        self.resize(240, 140)

        # 4. ä¸»è¦ä½ˆå±€ (åŒ…å«é‚Šè·ï¼Œè®“é™°å½±ä¸æœƒè¢«åˆ‡æ‰)
        main_layout = QVBoxLayout()
        main_layout.setContentsMargins(20, 20, 20, 20)

        # 5. å…§å®¹å®¹å™¨ (åŸæœ¬çš„ä»‹é¢æ¨£å¼ç§»åˆ°é€™è£¡)
        self.container = QWidget()
        self.container.setStyleSheet("""
            background-color: rgba(0, 0, 0, 180);
            border-radius: 15px;
            border: 2px solid #00ff00;
        """)
        
        # å®¹å™¨å…§çš„ä½ˆå±€
        container_layout = QVBoxLayout()
        self.label = QLabel("ç­‰å¾…å‘¼å«...")
        self.label.setFont(QFont('Microsoft JhengHei', 12))
        self.label.setWordWrap(True)
        self.label.setStyleSheet("color: white; background: transparent; border: none;")
        self.label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        
        container_layout.addWidget(self.label)
        self.container.setLayout(container_layout)
        
        main_layout.addWidget(self.container)
        self.setLayout(main_layout)

        # å°‡è¦–çª—ç§»å‹•åˆ°è¢å¹•å³ä¸‹è§’
        screen_geometry = QApplication.primaryScreen().availableGeometry()
        self.move(screen_geometry.width() - 260, screen_geometry.height() - 190)

    def update_status(self, text):
        """æ›´æ–° UI é¡¯ç¤ºæ–‡å­—"""
        self.label.setText(text)
        
        # åˆ¤æ–·æ˜¯å¦ç‚ºã€Œæ´»èºç‹€æ…‹ã€ (éŒ„éŸ³ä¸­ æˆ– VADå¾…å‘½ä¸­ æˆ– è½‰è­¯ä¸­)
        is_active = "è†è½ä¸­" in text or "VAD å¾…å‘½ä¸­" in text or "è½‰è­¯ä¸­" in text
        
        if is_active:
            # æ´»èºæ¨¡å¼ï¼šç´…è‰²èƒŒæ™¯ + ç™½è‰²ç™¼å…‰
            self.container.setStyleSheet("""
                background-color: rgba(255, 0, 0, 180);
                border-radius: 15px;
                border: 2px solid #ffffff;
            """)
            
            # åŠ å…¥ç™½è‰²ç™¼å…‰ç‰¹æ•ˆ (å°è¦–çª—)
            glow = QGraphicsDropShadowEffect()
            glow.setBlurRadius(20)
            glow.setColor(QColor(255, 255, 255))
            glow.setOffset(0, 0)
            self.container.setGraphicsEffect(glow)
            
            # é¡¯ç¤ºå…¨è¢å¹•é‚Šæ¡†ç‰¹æ•ˆ (æ·¡å…¥)
            self.overlay.fade_in()
            
        else:
            # å¾…æ©Ÿæ¨¡å¼ï¼šé»‘è‰²èƒŒæ™¯ + ç¶ è‰²é‚Šæ¡†
            self.container.setStyleSheet("""
                background-color: rgba(0, 0, 0, 180);
                border-radius: 15px;
                border: 2px solid #00ff00;
            """)
            self.container.setGraphicsEffect(None) # ç§»é™¤ç‰¹æ•ˆ
            
            # éš±è—å…¨è¢å¹•é‚Šæ¡†ç‰¹æ•ˆ (æ·¡å‡º)
            self.overlay.fade_out()

        self.show()

    def start_voice_recognition(self):
        """çœŸæ­£çš„èªéŸ³è­˜åˆ¥é‚è¼¯"""
        if self.vad_mode:
            self.status_signal.emit("âš ï¸ VAD æ¨¡å¼é–‹å•Ÿä¸­")
            return

        if self.listening: return
        self.listening = True
        
        # 1. å‘Šè¨´ä½¿ç”¨è€…é–‹å§‹äº†
        self.status_signal.emit("ğŸ”´ è†è½ä¸­...è«‹èªªè©±")
        
        # 2. åˆå§‹åŒ–è¾¨è­˜å™¨
        r = sr.Recognizer()
        
        try:
            with sr.Microphone() as source:
                # è‡ªå‹•èª¿æ•´ç’°å¢ƒå™ªéŸ³ (å»ºè­°åŠ ä¸Šé€™è¡Œï¼Œè¾¨è­˜æœƒæ¯”è¼ƒæº–)
                r.adjust_for_ambient_noise(source, duration=0.5)
                
                # é–‹å§‹éŒ„éŸ³ (é€™è£¡æœƒå¡ä½ç­‰å¾…ä½ èªªè©±çµæŸ)
                audio = r.listen(source, timeout=5, phrase_time_limit=10)
                
                self.status_signal.emit("ğŸ”„ è½‰è­¯ä¸­...")

                # 3. å‘¼å« Google èªéŸ³è¾¨è­˜ (éœ€é€£ç¶²)
                # language="zh-TW" æ˜¯é—œéµï¼Œè¨­å®šç‚ºç¹é«”ä¸­æ–‡
                text = r.recognize_google(audio, language="zh-TW")
                
                # 4. ã€é—œéµã€‘å°‡è¾¨è­˜åˆ°çš„æ–‡å­—ç™¼é€åˆ°ä»‹é¢é¡¯ç¤º
                self.status_signal.emit(f"ä½ èªªï¼š{text}")
                
                # é€™è£¡ä½ å¯ä»¥é †ä¾¿æŠŠ text æ‹¿å»åšå…¶ä»–äº‹ (ä¾‹å¦‚è¼¸å…¥åˆ°é›»è…¦)
                # print(f"è¾¨è­˜çµæœ: {text}")

        except sr.UnknownValueError:
            self.status_signal.emit("âŒ ç„¡æ³•è¾¨è­˜ (è½ä¸æ¸…æ¥š)")
        except sr.RequestError:
            self.status_signal.emit("âš ï¸ ç¶²è·¯éŒ¯èª¤æˆ– API é€£ç·šå¤±æ•—")
        except Exception as e:
            self.status_signal.emit(f"âš ï¸ éŒ¯èª¤: {e}")
        finally:
            self.listening = False
            # è¨­å®š 5 ç§’å¾Œè®Šå›ã€Œç­‰å¾…å‘¼å«ã€ï¼Œä¸ç„¶æ–‡å­—æœƒä¸€ç›´ç•™åœ¨ä¸Šé¢
            threading.Timer(5.0, lambda: self.status_signal.emit("ç­‰å¾…å‘¼å«...")).start()

    def toggle_vad_mode(self):
        """åˆ‡æ› VAD æ¨¡å¼"""
        self.vad_mode = not self.vad_mode
        if self.vad_mode:
            self.status_signal.emit("ğŸ™ï¸ VAD æ¨¡å¼å·²å•Ÿå‹•")
            if not self.vad_thread_running:
                threading.Thread(target=self.run_vad_loop, daemon=True).start()
        else:
            self.status_signal.emit("ğŸ›‘ VAD æ¨¡å¼å·²é—œé–‰")

    def run_vad_loop(self):
        """VAD å¾ªç’°ç›£è½"""
        if self.vad_thread_running: return
        self.vad_thread_running = True
        
        r = sr.Recognizer()
        
        try:
            with sr.Microphone() as source:
                self.status_signal.emit("èª¿æ•´ç’°å¢ƒå™ªéŸ³ä¸­...")
                r.adjust_for_ambient_noise(source, duration=1)
                
                while self.vad_mode:
                    if self.listening:
                        threading.Event().wait(0.5)
                        continue

                    try:
                        self.status_signal.emit("ğŸ‘‚ VAD å¾…å‘½ä¸­...")
                        # timeout=1: æ¯ç§’æª¢æŸ¥ä¸€æ¬¡æ˜¯å¦æœ‰äººèªªè©±
                        audio = r.listen(source, timeout=1, phrase_time_limit=10)
                        
                        self.listening = True
                        self.status_signal.emit("ğŸ”„ è½‰è­¯ä¸­...")
                        
                        try:
                            text = r.recognize_google(audio, language="zh-TW")
                            self.status_signal.emit(f"ä½ èªªï¼š{text}")
                        except sr.UnknownValueError:
                            pass
                        except sr.RequestError:
                            self.status_signal.emit("âš ï¸ ç¶²è·¯éŒ¯èª¤")
                        except Exception as e:
                            print(f"VAD Error: {e}")
                            
                    except sr.WaitTimeoutError:
                        continue
                    except Exception as e:
                        self.status_signal.emit(f"âš ï¸ éŒ¯èª¤: {e}")
                        threading.Event().wait(1)
                    finally:
                        self.listening = False
                        
        except Exception as e:
            self.status_signal.emit(f"âš ï¸ éº¥å…‹é¢¨éŒ¯èª¤: {e}")
            self.vad_mode = False
        finally:
            self.vad_thread_running = False

    def start_hotkey_listener(self):
        """åœ¨èƒŒæ™¯åŸ·è¡Œç·’ç›£è½éµç›¤"""
        def check_key():
            # è¨­å®šç†±éµç‚º Ctrl + Shift + V
            keyboard.add_hotkey('/', self.start_voice_recognition)
            # è¨­å®š VAD åˆ‡æ›ç†±éµç‚º F12
            keyboard.add_hotkey('f12', self.toggle_vad_mode)
            # è¨­å®šé€€å‡ºç†±éµç‚º Ctrl + Shift + Esc
            keyboard.add_hotkey('esc', lambda: QApplication.instance().quit())
            keyboard.wait()

        t = threading.Thread(target=check_key, daemon=True)
        t.start()

if __name__ == '__main__':
    app = QApplication(sys.argv)
    ex = VoiceAssistantWidget()
    ex.show()
    sys.exit(app.exec())