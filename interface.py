import sys
import os
import threading
import asyncio
import speech_recognition as sr
import ctypes # ä½¿ç”¨ ctypes å‘¼å« Win32 API é€²è¡ŒæŒ‰éµè¼ªè©¢
import time
from PyQt6.QtWidgets import QApplication, QWidget, QLabel, QVBoxLayout, QGraphicsDropShadowEffect
from PyQt6.QtCore import Qt, pyqtSignal, QTimer
from agent import get_agent_async, Runner, InMemorySessionService, InMemoryArtifactService, RunConfig, StreamingMode, types
from PyQt6.QtGui import QColor, QFont, QPainter, QPen, QConicalGradient, QBrush, QLinearGradient, QPixmap, QImage
from agent import get_screenshot_part

class ScreenGlowOverlay(QWidget):
    """å…¨è¢å¹•é‚Šæ¡†ç™¼å…‰ç‰¹æ•ˆè¦–çª— (éœ“è™¹æ³¢æµª + æ¼¸å±¤æ·¡å…¥æ·¡å‡ºç‰ˆ)"""
    def __init__(self):
        super().__init__()
        self.setWindowFlags(
            Qt.WindowType.FramelessWindowHint |
            Qt.WindowType.WindowStaysOnTopHint |
            Qt.WindowType.Tool |
            Qt.WindowType.WindowTransparentForInput
        )
        self.setAttribute(Qt.WidgetAttribute.WA_TranslucentBackground)
        self.setAttribute(Qt.WidgetAttribute.WA_TransparentForMouseEvents)
        self.setGeometry(QApplication.primaryScreen().geometry())

        # å‹•ç•«èˆ‡ç‰¹æ•ˆåƒæ•¸
        self.angle = 0
        self.opacity = 0.0
        self.target_opacity = 0.0
        self.border_width = 50 # åŠ å¯¬é‚Šæ¡†ä»¥é¡¯ç¤ºæ¼¸å±¤æ•ˆæœ
        self.mask_pixmap = None
        
        self.timer = QTimer(self)
        self.timer.timeout.connect(self.update_animation)

    def resizeEvent(self, event):
        # ç•¶è¢å¹•å¤§å°æ”¹è®Šæ™‚ï¼Œé‡æ–°ç”¢ç”Ÿé®ç½©
        self.generate_mask()
        super().resizeEvent(event)

    def generate_mask(self):
        """ç”¢ç”Ÿé‚Šç·£å¯¦å¿ƒã€å…§éƒ¨é€æ˜çš„é®ç½©"""
        if self.width() <= 0 or self.height() <= 0: return
        
        img = QImage(self.size(), QImage.Format.Format_ARGB32_Premultiplied)
        img.fill(Qt.GlobalColor.transparent)
        p = QPainter(img)
        bw = self.border_width
        w, h = self.width(), self.height()
        
        # å®šç¾©æ¼¸å±¤: 0.0(é‚Šç·£)=ä¸é€æ˜, 1.0(å…§éƒ¨)=é€æ˜
        # ä¸Šé‚Šæ¡†
        g_top = QLinearGradient(0, 0, 0, bw)
        g_top.setColorAt(0, QColor(255, 255, 255, 255))
        g_top.setColorAt(1, QColor(255, 255, 255, 0))
        p.fillRect(0, 0, w, bw, g_top)
        
        # ä¸‹é‚Šæ¡†
        g_bottom = QLinearGradient(0, h, 0, h - bw)
        g_bottom.setColorAt(0, QColor(255, 255, 255, 255))
        g_bottom.setColorAt(1, QColor(255, 255, 255, 0))
        p.fillRect(0, h - bw, w, bw, g_bottom)
        
        # å·¦é‚Šæ¡†
        g_left = QLinearGradient(0, 0, bw, 0)
        g_left.setColorAt(0, QColor(255, 255, 255, 255))
        g_left.setColorAt(1, QColor(255, 255, 255, 0))
        p.fillRect(0, 0, bw, h, g_left)
        
        # å³é‚Šæ¡†
        g_right = QLinearGradient(w, 0, w - bw, 0)
        g_right.setColorAt(0, QColor(255, 255, 255, 255))
        g_right.setColorAt(1, QColor(255, 255, 255, 0))
        p.fillRect(w - bw, 0, bw, h, g_right)
        
        p.end()
        self.mask_pixmap = QPixmap.fromImage(img)

    def fade_in(self):
        self.target_opacity = 1.0
        if not self.timer.isActive():
            self.show()
            self.timer.start(30)

    def fade_out(self):
        self.target_opacity = 0.0

    def update_animation(self):
        # 1. æ›´æ–°æ—‹è½‰è§’åº¦
        self.angle = (self.angle - 5) % 360

        # 2. æ›´æ–°é€æ˜åº¦ (æ·¡å…¥æ·¡å‡º)
        diff = self.target_opacity - self.opacity
        if abs(diff) < 0.05:
            self.opacity = self.target_opacity
            if self.opacity == 0.0:
                self.hide()
                self.timer.stop()
        else:
            self.opacity += diff * 0.2 # å¹³æ»‘éæ¸¡
            
        self.update()

    def paintEvent(self, event):
        if self.opacity <= 0 or not self.mask_pixmap: return

        # å»ºç«‹ä¸€å€‹æš«å­˜çš„ Pixmap ä¾†åˆæˆç‰¹æ•ˆ
        temp_pixmap = QPixmap(self.size())
        temp_pixmap.fill(Qt.GlobalColor.transparent)
        
        p = QPainter(temp_pixmap)
        p.setRenderHint(QPainter.RenderHint.Antialiasing)
        
        # æ­¥é©Ÿ A: å…ˆç•«å‡ºé®ç½© (æ±ºå®šå“ªè£¡è¦é¡¯ç¤º)
        p.drawPixmap(0, 0, self.mask_pixmap)
        
        # æ­¥é©Ÿ B: ä½¿ç”¨ SourceIn æ¨¡å¼å¡«å…¥éœ“è™¹è‰²å½©
        # (ä¿ç•™é®ç½©çš„ä¸é€æ˜åº¦ï¼Œä½†å°‡é¡è‰²æ›¿æ›ç‚ºæ¼¸å±¤)
        p.setCompositionMode(QPainter.CompositionMode.CompositionMode_SourceIn)
        
        center = self.rect().center()
        gradient = QConicalGradient(center.x(), center.y(), self.angle)
        gradient.setColorAt(0.00, QColor(0, 255, 255))   # Cyan
        gradient.setColorAt(0.25, QColor(0, 0, 255))     # Blue
        gradient.setColorAt(0.50, QColor(128, 0, 128))   # Purple
        gradient.setColorAt(0.75, QColor(255, 0, 255))   # Magenta
        gradient.setColorAt(1.00, QColor(0, 255, 255))   # Cyan
        
        p.setBrush(QBrush(gradient))
        p.setPen(Qt.PenStyle.NoPen)
        p.drawRect(self.rect())
        p.end()
        
        # æ­¥é©Ÿ C: å°‡åˆæˆå¥½çš„ Pixmap ç•«åˆ°è¢å¹•ä¸Šï¼Œä¸¦å¥—ç”¨å…¨åŸŸé€æ˜åº¦
        painter = QPainter(self)
        painter.setOpacity(self.opacity)
        painter.drawPixmap(0, 0, temp_pixmap)

class VoiceAssistantWidget(QWidget):
    # å®šç¾©ä¸€å€‹ä¿¡è™Ÿï¼Œç”¨ä¾†åœ¨é GUI åŸ·è¡Œç·’é€šçŸ¥ GUI æ›´æ–°
    status_signal = pyqtSignal(str)

    def __init__(self):
        super().__init__()
        self.initUI()
        
        # åˆå§‹åŒ–å…¨è¢å¹•ç‰¹æ•ˆ
        self.overlay = ScreenGlowOverlay()
        
        # åˆå§‹åŒ– AI Agent ç›¸é—œçµ„ä»¶
        self.agent = None
        self.loop = asyncio.new_event_loop()
        threading.Thread(target=self._run_async_loop, daemon=True).start()
        
        self.listening = False
        self.vad_mode = False  # VAD æ¨¡å¼ç‹€æ…‹
        self.vad_thread_running = False # é¿å…é‡è¤‡å•Ÿå‹• VAD åŸ·è¡Œç·’
        
        # é€£æ¥ä¿¡è™Ÿ
        self.status_signal.connect(self.update_status)

        # å•Ÿå‹•èƒŒæ™¯ç†±éµç›£è½
        self.start_hotkey_listener()

    def _run_async_loop(self):
        asyncio.set_event_loop(self.loop)
        self.loop.run_forever()

    def initUI(self):
        # 1. è¨­å®šè¦–çª—å±¬æ€§ï¼šç„¡é‚Šæ¡†ã€æ°¸é åœ¨æœ€ä¸Šå±¤
        self.setWindowFlags(Qt.WindowType.FramelessWindowHint | Qt.WindowType.WindowStaysOnTopHint | Qt.WindowType.Tool)
        
        # 2. è¨­å®šèƒŒæ™¯é€æ˜
        self.setAttribute(Qt.WidgetAttribute.WA_TranslucentBackground)

        # 3. èª¿æ•´è¦–çª—å¤§å° (ç¨å¾®åŠ å¤§ä»¥å®¹ç´ç™¼å…‰ç‰¹æ•ˆ)
        # æ”¹ç”¨ setMinimumSize é¿å…åœ¨é«˜ DPI ä¸‹è¢«å…§å®¹æ’é–‹å°è‡´å¹¾ä½•è¨­å®šéŒ¯èª¤
        self.setMinimumWidth(240)
        self.setMaximumWidth(600) # é™åˆ¶æœ€å¤§å¯¬åº¦ï¼Œå¼·åˆ¶é•·æ–‡å­—æ›è¡Œ

        # 4. ä¸»è¦ä½ˆå±€ (åŒ…å«é‚Šè·ï¼Œè®“é™°å½±ä¸æœƒè¢«åˆ‡æ‰)
        main_layout = QVBoxLayout()
        main_layout.setContentsMargins(20, 20, 20, 20)
        # è®“è¦–çª—å¤§å°æ ¹æ“šå…§å®¹è‡ªå‹•èª¿æ•´ (æœ€å°èˆ‡æœ€å¤§å°ºå¯¸é™åˆ¶å…§)
        main_layout.setSizeConstraint(QVBoxLayout.SizeConstraint.SetMinAndMaxSize)

        # 5. å…§å®¹å®¹å™¨ (åŸæœ¬çš„ä»‹é¢æ¨£å¼ç§»åˆ°é€™è£¡)
        self.container = QWidget()
        self.container.setStyleSheet("""
            background-color: rgba(0, 0, 0, 180);
            border-radius: 15px;
            border: 2px solid #00ff00;
        """)
        
        # å®¹å™¨å…§çš„ä½ˆå±€
        container_layout = QVBoxLayout()
        self.label = QLabel("ç­‰å¾…å‘¼å«...")
        self.label.setFont(QFont('Microsoft JhengHei', 12))
        self.label.setWordWrap(True)
        self.label.setStyleSheet("color: white; background: transparent; border: none;")
        self.label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        
        container_layout.addWidget(self.label)
        self.container.setLayout(container_layout)
        
        main_layout.addWidget(self.container)
        self.setLayout(main_layout)

        # å°‡è¦–çª—ç§»å‹•åˆ°è¢å¹•å·¦ä¸Šè§’
        screen_geometry = QApplication.primaryScreen().availableGeometry()
        self.move(20, 20)

    def update_status(self, text):
        """æ›´æ–° UI é¡¯ç¤ºæ–‡å­—"""
        self.label.setText(text)
        # å¼·åˆ¶èª¿æ•´è¦–çª—å¤§å°ä»¥é©æ‡‰æ–°æ–‡å­—
        self.adjustSize()
        
        # åˆ¤æ–·æ˜¯å¦ç‚ºã€Œæ´»èºç‹€æ…‹ã€ (éŒ„éŸ³ä¸­ æˆ– VADå¾…å‘½ä¸­ æˆ– è½‰è­¯ä¸­)
        is_active = "è†è½ä¸­" in text or "VAD å¾…å‘½ä¸­" in text or "è½‰è­¯ä¸­" in text
        
        if is_active:
            # æ´»èºæ¨¡å¼ï¼šç´…è‰²èƒŒæ™¯ + ç™½è‰²ç™¼å…‰
            self.container.setStyleSheet("""
                background-color: rgba(255, 0, 0, 180);
                border-radius: 15px;
                border: 2px solid #ffffff;
            """)
            
            # åŠ å…¥ç™½è‰²ç™¼å…‰ç‰¹æ•ˆ (å°è¦–çª—)
            glow = QGraphicsDropShadowEffect()
            glow.setBlurRadius(20)
            glow.setColor(QColor(255, 255, 255))
            glow.setOffset(0, 0)
            self.container.setGraphicsEffect(glow)
            
            # é¡¯ç¤ºå…¨è¢å¹•é‚Šæ¡†ç‰¹æ•ˆ (æ·¡å…¥)
            self.overlay.fade_in()
            
        else:
            # å¾…æ©Ÿæ¨¡å¼ï¼šé»‘è‰²èƒŒæ™¯ + ç¶ è‰²é‚Šæ¡†
            self.container.setStyleSheet("""
                background-color: rgba(0, 0, 0, 180);
                border-radius: 15px;
                border: 2px solid #00ff00;
            """)
            self.container.setGraphicsEffect(None) # ç§»é™¤ç‰¹æ•ˆ
            
            # éš±è—å…¨è¢å¹•é‚Šæ¡†ç‰¹æ•ˆ (æ·¡å‡º)
            self.overlay.fade_out()

        self.show()

    async def process_with_ai(self, text):
        """å°‡è¾¨è­˜å‡ºçš„æ–‡å­—é€äº¤ AI è™•ç†"""
        try:
            if self.agent is None:
                self.status_signal.emit("ğŸ¤– æ­£åœ¨åˆå§‹åŒ– AI...")
                self.agent = await get_agent_async("voice_session")
            
            self.status_signal.emit("ğŸ¤– AI æ€è€ƒä¸­...")
            
            session_service = InMemorySessionService()
            artifacts_service = InMemoryArtifactService()
            session = await session_service.create_session(state={}, app_name='voice_app', user_id="user")
            
            runner = Runner(
                app_name='voice_app',
                agent=self.agent,
                artifact_service=artifacts_service,
                session_service=session_service,
            )
            
            parts = [types.Part(text=text)]
            
            # åœ¨èªéŸ³å°è©±æ™‚ä¹Ÿè‡ªå‹•åŠ å…¥æˆªåœ–
            screenshot_part = get_screenshot_part()
            if screenshot_part:
                parts.append(screenshot_part)
            
            content = types.Content(role='user', parts=parts)
            full_response = ""
            
            async for event in runner.run_async(
                session_id=session.id,
                user_id=session.user_id,
                new_message=content,
                run_config=RunConfig(streaming_mode=StreamingMode.SSE, max_llm_calls=10)
            ):
                if event.content and event.partial:
                    text_part = event.content.parts[0].text
                    if text_part:
                        full_response += text_part
                        # å¯¦æ™‚æ›´æ–°é¡¯ç¤ºå…§å®¹
                        self.status_signal.emit(f"ğŸ¤– AIï¼š{full_response}")
                elif not event.partial and event.content:
                    # æœ€çµ‚å›æ‡‰å®Œæˆ
                    pass

        except Exception as e:
            self.status_signal.emit(f"âš ï¸ AI éŒ¯èª¤: {e}")

    def start_voice_recognition(self):
        """çœŸæ­£çš„èªéŸ³è­˜åˆ¥é‚è¼¯"""
        if self.vad_mode:
            self.status_signal.emit("âš ï¸ VAD æ¨¡å¼é–‹å•Ÿä¸­")
            return

        if self.listening: return
        self.listening = True
        
        def recognition_thread():
            self.status_signal.emit("ğŸ”´ è†è½ä¸­...è«‹èªªè©±")
            r = sr.Recognizer()
            try:
                with sr.Microphone() as source:
                    r.adjust_for_ambient_noise(source, duration=0.5)
                    audio = r.listen(source, timeout=5, phrase_time_limit=10)
                    self.status_signal.emit("ğŸ”„ è½‰è­¯ä¸­...")
                    text = r.recognize_google(audio, language="zh-TW")
                    self.status_signal.emit(f"ä½ èªªï¼š{text}")
                    
                    # ç•°æ­¥å‘¼å« AI è™•ç†
                    asyncio.run_coroutine_threadsafe(self.process_with_ai(text), self.loop)

            except sr.UnknownValueError:
                self.status_signal.emit("âŒ ç„¡æ³•è¾¨è­˜ (è½ä¸æ¸…æ¥š)")
                threading.Timer(3.0, lambda: self.status_signal.emit("ç­‰å¾…å‘¼å«...")).start()
            except sr.RequestError:
                self.status_signal.emit("âš ï¸ ç¶²è·¯éŒ¯èª¤")
                threading.Timer(3.0, lambda: self.status_signal.emit("ç­‰å¾…å‘¼å«...")).start()
            except Exception as e:
                self.status_signal.emit(f"âš ï¸ éŒ¯èª¤: {e}")
                threading.Timer(3.0, lambda: self.status_signal.emit("ç­‰å¾…å‘¼å«...")).start()
            finally:
                self.listening = False

        threading.Thread(target=recognition_thread, daemon=True).start()

    def toggle_vad_mode(self):
        """åˆ‡æ› VAD æ¨¡å¼"""
        self.vad_mode = not self.vad_mode
        if self.vad_mode:
            self.status_signal.emit("ğŸ™ï¸ VAD æ¨¡å¼å·²å•Ÿå‹•")
            if not self.vad_thread_running:
                threading.Thread(target=self.run_vad_loop, daemon=True).start()
        else:
            self.status_signal.emit("ğŸ›‘ VAD æ¨¡å¼å·²é—œé–‰")

    def run_vad_loop(self):
        """VAD å¾ªç’°ç›£è½"""
        if self.vad_thread_running: return
        self.vad_thread_running = True
        
        r = sr.Recognizer()
        
        try:
            with sr.Microphone() as source:
                self.status_signal.emit("èª¿æ•´ç’°å¢ƒå™ªéŸ³ä¸­...")
                r.adjust_for_ambient_noise(source, duration=1)
                
                while self.vad_mode:
                    if self.listening:
                        threading.Event().wait(0.5)
                        continue

                    try:
                        self.status_signal.emit("ğŸ‘‚ VAD å¾…å‘½ä¸­...")
                        # timeout=1: æ¯ç§’æª¢æŸ¥ä¸€æ¬¡æ˜¯å¦æœ‰äººèªªè©±
                        audio = r.listen(source, timeout=1, phrase_time_limit=10)
                        
                        self.listening = True
                        self.status_signal.emit("ğŸ”„ è½‰è­¯ä¸­...")
                        
                        try:
                            text = r.recognize_google(audio, language="zh-TW")
                            self.status_signal.emit(f"ä½ èªªï¼š{text}")
                            # VAD æ¨¡å¼ä¹Ÿä¸²æ¥ AI
                            asyncio.run_coroutine_threadsafe(self.process_with_ai(text), self.loop)
                        except sr.UnknownValueError:
                            pass
                        except sr.RequestError:
                            self.status_signal.emit("âš ï¸ ç¶²è·¯éŒ¯èª¤")
                        except Exception as e:
                            print(f"VAD Error: {e}")
                            
                    except sr.WaitTimeoutError:
                        continue
                    except Exception as e:
                        self.status_signal.emit(f"âš ï¸ éŒ¯èª¤: {e}")
                        threading.Event().wait(1)
                    finally:
                        self.listening = False
                        
        except Exception as e:
            self.status_signal.emit(f"âš ï¸ éº¥å…‹é¢¨éŒ¯èª¤: {e}")
            self.vad_mode = False
        finally:
            self.vad_thread_running = False

    def start_hotkey_listener(self):
        """åœ¨èƒŒæ™¯åŸ·è¡Œç·’ä½¿ç”¨ GetAsyncKeyState è¼ªè©¢ç›£è½éµç›¤"""
        def check_key():
            # å®šç¾©è™›æ“¬éµç¢¼ (Virtual-Key Codes)
            VK_OEM_2 = 0xBF # '/?' éµ
            VK_DIVIDE = 0x6F # æ•¸å­—éµç›¤ '/' éµ
            VK_F12 = 0x7B
            VK_ESCAPE = 0x1B
            
            while True:
                try:
                    # æª¢æŸ¥ '/' éµ (ä¸»éµç›¤æˆ–æ•¸å­—éµç›¤)
                    if (ctypes.windll.user32.GetAsyncKeyState(VK_OEM_2) & 0x8000) or \
                       (ctypes.windll.user32.GetAsyncKeyState(VK_DIVIDE) & 0x8000):
                        # å‘¼å«èªéŸ³è¾¨è­˜
                        # ä½¿ç”¨ QTimer.singleShot åœ¨ä¸»åŸ·è¡Œç·’è§¸ç™¼ï¼Œé¿å…åŸ·è¡Œç·’å®‰å…¨å•é¡Œ
                        # ä½†é€™è£¡åŸæœ¬é‚è¼¯æ˜¯ç›´æ¥å‘¼å«ï¼Œä¸” start_voice_recognition å…§éƒ¨æœ‰é–ï¼Œæš«æ™‚ä¿æŒç›´æ¥å‘¼å«
                        if not self.listening and not self.vad_mode:
                            self.start_voice_recognition()
                            time.sleep(0.5) # ç°¡å–®é˜²æŠ–å‹•
                    
                    # æª¢æŸ¥ F12
                    elif ctypes.windll.user32.GetAsyncKeyState(VK_F12) & 0x8000:
                        self.toggle_vad_mode()
                        time.sleep(0.5) # ç°¡å–®é˜²æŠ–å‹•
                        
                    # æª¢æŸ¥ ESC (é€€å‡º)
                    elif ctypes.windll.user32.GetAsyncKeyState(VK_ESCAPE) & 0x8000:
                        QApplication.instance().quit()
                        break
                        
                    time.sleep(0.05) # 20Hz æ¡æ¨£ç‡ï¼Œé™ä½ CPU ä½¿ç”¨ç‡
                except Exception as e:
                    print(f"Hotkey Error: {e}")
                    time.sleep(1)

        t = threading.Thread(target=check_key, daemon=True)
        t.start()

if __name__ == '__main__':
    # è§£æ±º DPI ç¸®æ”¾å•é¡Œ
    os.environ["QT_AUTO_SCREEN_SCALE_FACTOR"] = "1"
    
    app = QApplication(sys.argv)
    
    # è¨­å®š DPI ç¸®æ”¾ç­–ç•¥
    app.setHighDpiScaleFactorRoundingPolicy(Qt.HighDpiScaleFactorRoundingPolicy.PassThrough)
    
    ex = VoiceAssistantWidget()
    ex.show()
    sys.exit(app.exec())